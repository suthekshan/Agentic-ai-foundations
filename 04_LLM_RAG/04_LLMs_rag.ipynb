{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2d657735",
      "metadata": {
        "id": "2d657735"
      },
      "source": [
        "# From LLMs to the Breakdown of RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be02827",
      "metadata": {
        "id": "9be02827"
      },
      "source": [
        "## What is a Large Language Model (LLM)?\n",
        "\n",
        "A **Large Language Model (LLM)** is a type of artificial intelligence that understands and generates human language.\n",
        "\n",
        "It learns patterns from massive amounts of text (books, articles, code, etc.) and uses those patterns to predict the **next most likely word** in a sequence.\n",
        "\n",
        "---\n",
        "\n",
        "## How an LLM Works\n",
        "\n",
        "1. You give the model some text (a **prompt**)\n",
        "2. The model processes the text using learned patterns\n",
        "3. It predicts the next word, then the next, and so on\n",
        "4. The result is a coherent **response**\n",
        "\n",
        "### Key Terms\n",
        "\n",
        "- **Prompt**: Input text given to the model\n",
        "- **Completion**: Text generated by the model\n",
        "- **Tokens**: Pieces of text (words or word fragments)\n",
        "- **Context Window**: How much text the model can remember at once\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "587042d7",
      "metadata": {
        "id": "587042d7"
      },
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/0*O5X15ycTtapwnzgc.png\" alt=\"LLM timeline\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c79eed9",
      "metadata": {
        "id": "4c79eed9"
      },
      "source": [
        "Set API Key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install the Groq client library\n",
        "!pip install -q groq\n",
        "\n",
        "# 2. Import necessary libraries\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from groq import Groq\n",
        "\n",
        "try:\n",
        "    api_key = userdata.get('GROQ_API_KEY')\n",
        "except:\n",
        "    api_key = \"gsk_...\"\n",
        "\n",
        "client = Groq(api_key=api_key)\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is machine learning?\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.5,\n",
        "    max_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=False,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "# 5. Print the result\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "SC4nJOzJANTb"
      },
      "id": "SC4nJOzJANTb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG System\n"
      ],
      "metadata": {
        "id": "UDp4w0Xm9HkB"
      },
      "id": "UDp4w0Xm9HkB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://github.com/suthekshan/Agentic-Ai-Foundations/blob/main/04_LLM_RAG/images/rag1.png?raw=1)\n"
      ],
      "metadata": {
        "id": "sNlplMKT9IuQ"
      },
      "id": "sNlplMKT9IuQ"
    },
    {
      "cell_type": "markdown",
      "id": "16809365",
      "metadata": {
        "id": "16809365"
      },
      "source": [
        "\n",
        "- PDF document ingestion\n",
        "- Text chunking\n",
        "- Hugging Face embeddings\n",
        "- ChromaDB vector store\n",
        "- LLM for Domain Specific grounded question answering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84d40f07",
      "metadata": {
        "id": "84d40f07"
      },
      "source": [
        "<img src=\"https://github.com/suthekshan/Agentic-Ai-Foundations/blob/main/04_LLM_RAG/images/RAG.jpg?raw=1\" alt=\"LLM timeline\" width=\"800\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30862429",
      "metadata": {
        "id": "30862429"
      },
      "outputs": [],
      "source": [
        "!pip install -q \\\n",
        "  langchain \\\n",
        "  langchain-core \\\n",
        "  langchain-community \\\n",
        "  langchain-chroma \\\n",
        "  langchain-text-splitters \\\n",
        "  langchain-groq \\\n",
        "  langchain-huggingface \\\n",
        "  sentence-transformers \\\n",
        "  pypdf \\\n",
        "  python-dotenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3c45225",
      "metadata": {
        "id": "c3c45225"
      },
      "source": [
        "## üîê Environment Setup\n",
        "\n",
        "Create a `.env` file  with:\n",
        "\n",
        "        GROQ_API_KEY=your_groq_api_key_here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e91f23b4",
      "metadata": {
        "id": "e91f23b4",
        "outputId": "3777784a-51cf-4a86-9689-b2be1aa28e90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55647f6b",
      "metadata": {
        "id": "55647f6b"
      },
      "source": [
        "## Data ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1073a6fa",
      "metadata": {
        "id": "1073a6fa"
      },
      "source": [
        "<img src=\"https://github.com/suthekshan/Agentic-Ai-Foundations/blob/main/04_LLM_RAG/images/data_ingestion.png?raw=1\" alt=\"LLM timeline\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df0f672",
      "metadata": {
        "id": "3df0f672"
      },
      "source": [
        "## üìÑ Load PDF Document\n",
        "\n",
        "We load the PDF using `PyPDFLoader`.  \n",
        "Each page becomes a `Document` object with metadata.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "6emYVS7apgMn"
      },
      "id": "6emYVS7apgMn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "403cd225",
      "metadata": {
        "id": "403cd225",
        "outputId": "90c00a40-b94c-40ab-a4da-7f6e91a893e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "271"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "pdf_path = \"/MyDrive/Agentic-AIOT-Workshop/pdf1.pdf\"   # <- update if needed\n",
        "pdf_path = \"pdf1.pdf\"  # change if needed\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "\n",
        "len(documents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6b6718a",
      "metadata": {
        "id": "a6b6718a"
      },
      "source": [
        "## ‚úÇÔ∏è Text Chunking\n",
        "\n",
        "The document is split into overlapping chunks to improve retrieval accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203673ab",
      "metadata": {
        "id": "203673ab",
        "outputId": "6173bcd7-55b8-422d-f102-455f46ff0c4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "265"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(documents)\n",
        "len(texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e61a4240",
      "metadata": {
        "id": "e61a4240"
      },
      "source": [
        "## üß† Embedding Model (Hugging Face)\n",
        "\n",
        "\n",
        "\n",
        "The embeddings are stored in ChromaDB.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e49c7f",
      "metadata": {
        "id": "98e49c7f"
      },
      "source": [
        "üí° Always use the same embedding model for a given Chroma directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "405fc195",
      "metadata": {
        "id": "405fc195"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bab2304",
      "metadata": {
        "id": "4bab2304"
      },
      "source": [
        "## üíæ ChromaDb Vector Store\n",
        "\n",
        "ChromaDB persists vectors on disk so embeddings are reused across runs.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"pdf_collection\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_pdf_db\"\n",
        ")\n",
        "\n",
        "# Add documents only once\n",
        "if vector_store._collection.count() == 0:\n",
        "    vector_store.add_documents(texts)"
      ],
      "metadata": {
        "id": "BFscKzdus6ko"
      },
      "id": "BFscKzdus6ko",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f14f1f33",
      "metadata": {
        "id": "f14f1f33"
      },
      "source": [
        "## üîç Retriever\n",
        "\n",
        "The retriever fetches the most relevant chunks for a given query.\n",
        "\n",
        "\n",
        "![Alt text](https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fi6gsuxui6aagm90wfnmr.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe5d62e",
      "metadata": {
        "id": "afe5d62e"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f44732",
      "metadata": {
        "id": "60f44732"
      },
      "source": [
        "##   `k` in Retriever\n",
        "\n",
        "- `k` = number of most similar document chunks retrieved\n",
        "- Larger `k` ‚Üí more context, but more noise\n",
        "- Smaller `k` ‚Üí precise, but may miss info\n",
        "\n",
        "changing `k` affects the number of retrieved documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf76b86",
      "metadata": {
        "id": "1bf76b86",
        "outputId": "0365130d-5109-44da-e21b-20ad99ba1083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Retrieved with k=1:\n",
            "Number of documents retrieved: 1\n",
            "\n",
            "--- Document 1 ---\n",
            "Content preview: History\n",
            "Topic Civilization & Culture\n",
            "Subtopic\n",
            "A History of India\n",
            "Professor Michael H. Fisher\n",
            "Oberlin College\n",
            "Course Guidebook...\n",
            " Retrieved with k=3:\n",
            "Number of documents retrieved: 3\n",
            "\n",
            "--- Document 1 ---\n",
            "Content preview: History\n",
            "Topic Civilization & Culture\n",
            "Subtopic\n",
            "A History of India\n",
            "Professor Michael H. Fisher\n",
            "Oberlin College\n",
            "Course Guidebook...\n",
            "\n",
            "--- Document 2 ---\n",
            "Content preview: leCTure 29‚ÄînaTionalisTs aMbedkar, bose, and JinnaH \n",
            "247\n",
            "SuggeSted Reading\n",
            "Bose, His Majesty‚Äôs Opponent.\n",
            "Jaffrelot, Dr. Ambedkar and Untouchability.\n",
            "Ja...\n",
            "\n",
            "--- Document 3 ---\n",
            "Content preview: v\n",
            "Table of ConTenTs \n",
            "LECTURE 24\n",
            "The British East India Company ............................... 194\n",
            "LECTURE 25\n",
            "The Issues and Events of 1857 .............\n",
            " Retrieved with k=5:\n",
            "Number of documents retrieved: 5\n",
            "\n",
            "--- Document 1 ---\n",
            "Content preview: History\n",
            "Topic Civilization & Culture\n",
            "Subtopic\n",
            "A History of India\n",
            "Professor Michael H. Fisher\n",
            "Oberlin College\n",
            "Course Guidebook...\n",
            "\n",
            "--- Document 2 ---\n",
            "Content preview: leCTure 29‚ÄînaTionalisTs aMbedkar, bose, and JinnaH \n",
            "247\n",
            "SuggeSted Reading\n",
            "Bose, His Majesty‚Äôs Opponent.\n",
            "Jaffrelot, Dr. Ambedkar and Untouchability.\n",
            "Ja...\n",
            "\n",
            "--- Document 3 ---\n",
            "Content preview: v\n",
            "Table of ConTenTs \n",
            "LECTURE 24\n",
            "The British East India Company ............................... 194\n",
            "LECTURE 25\n",
            "The Issues and Events of 1857 .............\n",
            "\n",
            "--- Document 4 ---\n",
            "Content preview: leCTure 24‚ÄîTHe briTisH easT india CoMpany \n",
            "203\n",
            "should be educated in their own languages. By ‚Äúeducation,‚Äù both \n",
            "sides really meant the education of a ...\n",
            "\n",
            "--- Document 5 ---\n",
            "Content preview: vi\n",
            "A History of indiA\n",
            "SUPPLEMENTAL MATERIAL\n",
            "Bibliography ................................................ 309\n",
            "Image Credits .............................\n"
          ]
        }
      ],
      "source": [
        "# Test query\n",
        "test_query = \"What is the main topic of this document?\"\n",
        "\n",
        "# Try different k values\n",
        "k_values = [1, 3, 5]\n",
        "\n",
        "for k in k_values:\n",
        "    # Create retriever with specific k\n",
        "    retriever_k = vector_store.as_retriever(search_kwargs={\"k\": k})\n",
        "\n",
        "    # Retrieve documents\n",
        "    retrieved_docs = retriever_k.invoke(test_query)\n",
        "\n",
        "    print(f\" Retrieved with k={k}:\")\n",
        "    print(f\"Number of documents retrieved: {len(retrieved_docs)}\")\n",
        "\n",
        "    for i, doc in enumerate(retrieved_docs, 1):\n",
        "        print(f\"\\n--- Document {i} ---\")\n",
        "        print(f\"Content preview: {doc.page_content[:150]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a007788",
      "metadata": {
        "id": "7a007788"
      },
      "source": [
        "## ‚ö° Groq LLM\n",
        "\n",
        "We use Groq‚Äôs hosted LLM.  \n",
        "Model runs remotely and is not stored locally.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e64179",
      "metadata": {
        "id": "99e64179"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb0a0408",
      "metadata": {
        "id": "eb0a0408"
      },
      "source": [
        "## üìù Prompt Template\n",
        "\n",
        "The LLM is instructed to answer strictly from retrieved context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Alt text](https://xaviercollantes.dev/_next/image?url=%2Fassets%2Fimages%2Frag-langchain%2Fdoge.webp&w=3840&q=75)"
      ],
      "metadata": {
        "id": "c5FgDDVoAWt7"
      },
      "id": "c5FgDDVoAWt7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98505a69",
      "metadata": {
        "id": "98505a69"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"Use ONLY the context below to answer the question.\n",
        "If the answer is not present in the context, say:\n",
        "\"I do not know based on the provided document.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(prompt_template)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28450ccb",
      "metadata": {
        "id": "28450ccb"
      },
      "source": [
        "## üîó RAG Chain\n",
        "\n",
        "The pipeline:\n",
        "Retriever ‚Üí Prompt ‚Üí LLM ‚Üí Output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b412f9c8",
      "metadata": {
        "id": "b412f9c8"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(\n",
        "        f\"Page {doc.metadata.get('page', 'N/A')}:\\n{doc.page_content}\"\n",
        "        for doc in docs\n",
        "    )\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"query\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a7fab8",
      "metadata": {
        "id": "43a7fab8"
      },
      "source": [
        "## ‚ùì Ask Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53aa1157",
      "metadata": {
        "id": "53aa1157",
        "outputId": "1a11d0f1-bb36-469b-c00a-cecefa346549"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I do not know based on the provided document.'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\n",
        "    \"What does the document say about Ukraine?\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb7c43e",
      "metadata": {
        "id": "6cb7c43e"
      },
      "source": [
        "## üö´ Out-of-Context Question\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d72dc6",
      "metadata": {
        "id": "15d72dc6",
        "outputId": "ae9d6a7d-2202-43e0-9579-edfef0d804e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I do not know based on the provided document.'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\n",
        "    \"What does the document say about Ukraine?\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}